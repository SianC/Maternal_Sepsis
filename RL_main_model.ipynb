{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -U protobuf==3.8.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sianc\\anaconda3\\envs\\willthiswork\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\sianc\\anaconda3\\envs\\willthiswork\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\sianc\\anaconda3\\envs\\willthiswork\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\sianc\\anaconda3\\envs\\willthiswork\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\sianc\\anaconda3\\envs\\willthiswork\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\sianc\\anaconda3\\envs\\willthiswork\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\sianc\\anaconda3\\envs\\willthiswork\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\sianc\\anaconda3\\envs\\willthiswork\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\sianc\\anaconda3\\envs\\willthiswork\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\sianc\\anaconda3\\envs\\willthiswork\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\sianc\\anaconda3\\envs\\willthiswork\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\sianc\\anaconda3\\envs\\willthiswork\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "try:\n",
    "    import cPickle as pickle\n",
    "except ImportError:\n",
    "    import _pickle as pickle\n",
    "import copy\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#These are the features as in Yan's paper.\n",
    "#state_features = ['gender','mechvent','re_admission', 'age','Weight_kg','GCS','HR','SysBP','MeanBP',\n",
    "#                  'DiaBP','RR','Temp_C','FiO2_1','Potassium','Sodium','Chloride','Glucose','Magnesium','Calcium','Hb',\n",
    "#                  'WBC_count','Platelets_count','PTT','PT','Arterial_pH','paO2','paCO2','Arterial_BE','HCO3',\n",
    "#                  'Arterial_lactate','SOFA','SIRS','Shock_Index','PaO2_FiO2','cumulated_balance', 'SpO2','BUN',\n",
    "#                  'Creatinine','SGOT','SGPT','Total_bili','INR','input_total','input_4hourly','output_total', \n",
    "#                  'output_4hourly']\n",
    "\n",
    "state_features = ['gender','mechvent','max_dose_vaso','re_admission','age',\n",
    "    'Weight_kg','GCS','HR','SysBP','MeanBP','DiaBP','RR','Temp_C','FiO2_1',\n",
    "    'Potassium','Sodium','Chloride','Glucose','Magnesium','Calcium',\n",
    "    'Hb','WBC_count','Platelets_count','PTT','PT','Arterial_pH','paO2','paCO2',\n",
    "    'Arterial_BE','HCO3','Arterial_lactate','SOFA','SIRS','Shock_Index','PaO2_FiO2',\n",
    "    'cumulated_balance', 'SpO2','BUN','Creatinine','SGOT','SGPT','Total_bili','INR',\n",
    "    'input_total','input_4hourly','output_total','output_4hourly','abchange_vc'] # removed END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(state_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../Fresh_start/rl_train_set_scaled_rewarded_abchange.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df.drop(\"elixhauser\", axis=1)\n",
    "# df = df.drop(\"died_in_hosp\", axis=1)\n",
    "# df = df.drop(\"delay_end_of_record_and_discharge_or_death\", axis=1)\n",
    "# df = df.drop(\"died_within_48h_of_out_time\", axis=1)\n",
    "# df = df.drop(\"Ionised_Ca\", axis=1)\n",
    "# df = df.drop(\"CO2_mEqL\", axis=1)\n",
    "# df = df.drop(\"Albumin\", axis=1)\n",
    "# df = df.drop(\"charttime\", axis=1)\n",
    "# list_of_nan = []\n",
    "# for i, row in df.iterrows():\n",
    "#     if pd.isnull(row[\"bloc\"]):\n",
    "#             #print(i)\n",
    "#         list_of_nan.append(i)\n",
    "#             #print(list_of_nan)\n",
    "# df = df.drop(list_of_nan)\n",
    "# df = df.fillna(0)\n",
    "# df.index = range(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "170.02700000000004"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(df[\"abchange_vc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = df.columns.tolist()\n",
    "#columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,len(columns)):\n",
    "    df[columns[i]] = pd.to_numeric(df[columns[i]])\n",
    "#df[\"action\"] = pd.to_numeric(df[\"action\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df = pd.read_csv('../Fresh_start/rl_val_set_scaled_rewarded_abchange.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('../Fresh_start/rl_test_set_scaled_rewarded_abchange.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "preg_df = pd.read_csv('../Fresh_start/rl_pregnant_set_scaled_rewarded_abchange.csv')\n",
    "control_1_df = pd.read_csv('../Fresh_start/rl_control_1_set_scaled_rewarded_abchange.csv')\n",
    "control_2_df = pd.read_csv('../Fresh_start/rl_control_2_set_scaled_rewarded_abchange.csv')\n",
    "old_df = pd.read_csv('../Fresh_start/rl_old_set_scaled_rewarded_abchange.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level_0</th>\n",
       "      <th>index</th>\n",
       "      <th>bloc</th>\n",
       "      <th>icustayid</th>\n",
       "      <th>charttime</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>elixhauser</th>\n",
       "      <th>re_admission</th>\n",
       "      <th>died_in_hosp</th>\n",
       "      <th>...</th>\n",
       "      <th>output_4hourly</th>\n",
       "      <th>cumulated_balance</th>\n",
       "      <th>SOFA</th>\n",
       "      <th>SIRS</th>\n",
       "      <th>vaso_input</th>\n",
       "      <th>iv_input</th>\n",
       "      <th>action</th>\n",
       "      <th>reward</th>\n",
       "      <th>max_dose_vaso_unnorm</th>\n",
       "      <th>abchange_vc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5483</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1805</td>\n",
       "      <td>5378977200</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.042253</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.392265</td>\n",
       "      <td>0.260870</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.644751</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5484</td>\n",
       "      <td>0.222560</td>\n",
       "      <td>1805</td>\n",
       "      <td>5378991600</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.042253</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.775557</td>\n",
       "      <td>0.391488</td>\n",
       "      <td>0.173913</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>15</td>\n",
       "      <td>0.707625</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5485</td>\n",
       "      <td>0.356608</td>\n",
       "      <td>1805</td>\n",
       "      <td>5379006000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.042253</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.765525</td>\n",
       "      <td>0.391129</td>\n",
       "      <td>0.130435</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>20</td>\n",
       "      <td>-1.692309</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>5486</td>\n",
       "      <td>0.452837</td>\n",
       "      <td>1805</td>\n",
       "      <td>5379020400</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.042253</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.662998</td>\n",
       "      <td>0.391440</td>\n",
       "      <td>0.130435</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>20</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5487</td>\n",
       "      <td>0.527957</td>\n",
       "      <td>1805</td>\n",
       "      <td>5379034800</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.042253</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.668160</td>\n",
       "      <td>0.392331</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>20</td>\n",
       "      <td>0.799234</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>971</th>\n",
       "      <td>971</td>\n",
       "      <td>277871</td>\n",
       "      <td>0.923625</td>\n",
       "      <td>99753</td>\n",
       "      <td>5710093200</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.108613</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.669813</td>\n",
       "      <td>0.371922</td>\n",
       "      <td>0.173913</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10</td>\n",
       "      <td>-1.468337</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>972</th>\n",
       "      <td>972</td>\n",
       "      <td>277872</td>\n",
       "      <td>0.944365</td>\n",
       "      <td>99753</td>\n",
       "      <td>5710107600</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.108613</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.669813</td>\n",
       "      <td>0.371671</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10</td>\n",
       "      <td>2.018612</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>973</th>\n",
       "      <td>973</td>\n",
       "      <td>277873</td>\n",
       "      <td>0.963927</td>\n",
       "      <td>99753</td>\n",
       "      <td>5710122000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.108613</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.638505</td>\n",
       "      <td>0.371515</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>974</th>\n",
       "      <td>974</td>\n",
       "      <td>277874</td>\n",
       "      <td>0.982436</td>\n",
       "      <td>99753</td>\n",
       "      <td>5710136400</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.108613</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.622985</td>\n",
       "      <td>0.371396</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10</td>\n",
       "      <td>-1.128242</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>975</th>\n",
       "      <td>975</td>\n",
       "      <td>277875</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>99753</td>\n",
       "      <td>5710150800</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.108613</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.371408</td>\n",
       "      <td>0.217391</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>976 rows × 67 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     level_0   index      bloc  icustayid   charttime  gender       age  \\\n",
       "0          0    5483  0.000000       1805  5378977200     1.0  0.042253   \n",
       "1          1    5484  0.222560       1805  5378991600     1.0  0.042253   \n",
       "2          2    5485  0.356608       1805  5379006000     1.0  0.042253   \n",
       "3          3    5486  0.452837       1805  5379020400     1.0  0.042253   \n",
       "4          4    5487  0.527957       1805  5379034800     1.0  0.042253   \n",
       "..       ...     ...       ...        ...         ...     ...       ...   \n",
       "971      971  277871  0.923625      99753  5710093200     1.0  0.108613   \n",
       "972      972  277872  0.944365      99753  5710107600     1.0  0.108613   \n",
       "973      973  277873  0.963927      99753  5710122000     1.0  0.108613   \n",
       "974      974  277874  0.982436      99753  5710136400     1.0  0.108613   \n",
       "975      975  277875  1.000000      99753  5710150800     1.0  0.108613   \n",
       "\n",
       "     elixhauser  re_admission  died_in_hosp  ...  output_4hourly  \\\n",
       "0      0.000000           0.0           NaN  ...        0.000000   \n",
       "1      0.000000           0.0           NaN  ...        0.775557   \n",
       "2      0.000000           0.0           NaN  ...        0.765525   \n",
       "3      0.000000           0.0           NaN  ...        0.662998   \n",
       "4      0.000000           0.0           NaN  ...        0.668160   \n",
       "..          ...           ...           ...  ...             ...   \n",
       "971    0.384615           0.0           NaN  ...        0.669813   \n",
       "972    0.384615           0.0           NaN  ...        0.669813   \n",
       "973    0.384615           0.0           NaN  ...        0.638505   \n",
       "974    0.384615           0.0           NaN  ...        0.622985   \n",
       "975    0.384615           0.0           NaN  ...        0.000000   \n",
       "\n",
       "     cumulated_balance      SOFA  SIRS  vaso_input  iv_input  action  \\\n",
       "0             0.392265  0.260870  0.75         0.0       0.0       0   \n",
       "1             0.391488  0.173913  0.50         0.0       3.0      15   \n",
       "2             0.391129  0.130435  0.75         0.0       4.0      20   \n",
       "3             0.391440  0.130435  0.75         0.0       4.0      20   \n",
       "4             0.392331  0.043478  0.50         0.0       4.0      20   \n",
       "..                 ...       ...   ...         ...       ...     ...   \n",
       "971           0.371922  0.173913  0.50         0.0       2.0      10   \n",
       "972           0.371671  0.043478  0.50         0.0       2.0      10   \n",
       "973           0.371515  0.000000  1.00         0.0       2.0      10   \n",
       "974           0.371396  0.000000  1.00         0.0       2.0      10   \n",
       "975           0.371408  0.217391  1.00         0.0       1.0       5   \n",
       "\n",
       "        reward  max_dose_vaso_unnorm  abchange_vc  \n",
       "0     0.644751                   0.0          0.0  \n",
       "1     0.707625                   0.0          0.0  \n",
       "2    -1.692309                   0.0          0.0  \n",
       "3     0.250000                   0.0          0.0  \n",
       "4     0.799234                   0.0          0.0  \n",
       "..         ...                   ...          ...  \n",
       "971  -1.468337                   0.0          0.0  \n",
       "972   2.018612                   0.0          0.0  \n",
       "973   0.000000                   0.0          0.0  \n",
       "974  -1.128242                   0.0          0.0  \n",
       "975  15.000000                   0.0          0.0  \n",
       "\n",
       "[976 rows x 67 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preg_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>bloc</th>\n",
       "      <th>icustayid</th>\n",
       "      <th>charttime</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>elixhauser</th>\n",
       "      <th>re_admission</th>\n",
       "      <th>died_in_hosp</th>\n",
       "      <th>died_within_48h_of_out_time</th>\n",
       "      <th>...</th>\n",
       "      <th>output_4hourly</th>\n",
       "      <th>cumulated_balance</th>\n",
       "      <th>SOFA</th>\n",
       "      <th>SIRS</th>\n",
       "      <th>vaso_input</th>\n",
       "      <th>iv_input</th>\n",
       "      <th>action</th>\n",
       "      <th>reward</th>\n",
       "      <th>max_dose_vaso_unnorm</th>\n",
       "      <th>abchange_vc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11</td>\n",
       "      <td>6898241400</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.902277</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.392265</td>\n",
       "      <td>0.478261</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.383136</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.222560</td>\n",
       "      <td>11</td>\n",
       "      <td>6898255800</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.902277</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.718397</td>\n",
       "      <td>0.391715</td>\n",
       "      <td>0.391304</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.271041</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.356608</td>\n",
       "      <td>11</td>\n",
       "      <td>6898270200</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.902277</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.735149</td>\n",
       "      <td>0.391045</td>\n",
       "      <td>0.304348</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.884898</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.452837</td>\n",
       "      <td>11</td>\n",
       "      <td>6898284600</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.902277</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.738138</td>\n",
       "      <td>0.390351</td>\n",
       "      <td>0.347826</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.025000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.527957</td>\n",
       "      <td>11</td>\n",
       "      <td>6898299000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.902277</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.710650</td>\n",
       "      <td>0.389849</td>\n",
       "      <td>0.347826</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.025000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110402</th>\n",
       "      <td>110402</td>\n",
       "      <td>0.923625</td>\n",
       "      <td>99984</td>\n",
       "      <td>6807758400</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.829460</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.747842</td>\n",
       "      <td>0.364055</td>\n",
       "      <td>0.217391</td>\n",
       "      <td>0.75</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.025000</td>\n",
       "      <td>0.113</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110403</th>\n",
       "      <td>110403</td>\n",
       "      <td>0.944365</td>\n",
       "      <td>99984</td>\n",
       "      <td>6807772800</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.829460</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.770689</td>\n",
       "      <td>0.363038</td>\n",
       "      <td>0.217391</td>\n",
       "      <td>0.50</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.740110</td>\n",
       "      <td>0.113</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110404</th>\n",
       "      <td>110404</td>\n",
       "      <td>0.963927</td>\n",
       "      <td>99984</td>\n",
       "      <td>6807787200</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.829460</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.742432</td>\n",
       "      <td>0.362308</td>\n",
       "      <td>0.304348</td>\n",
       "      <td>0.50</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.183736</td>\n",
       "      <td>0.113</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110405</th>\n",
       "      <td>110405</td>\n",
       "      <td>0.982436</td>\n",
       "      <td>99984</td>\n",
       "      <td>6807801600</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.829460</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.723777</td>\n",
       "      <td>0.361722</td>\n",
       "      <td>0.304348</td>\n",
       "      <td>0.50</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.634898</td>\n",
       "      <td>0.113</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110406</th>\n",
       "      <td>110406</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>99984</td>\n",
       "      <td>6807816000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.829460</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.734385</td>\n",
       "      <td>0.361058</td>\n",
       "      <td>0.347826</td>\n",
       "      <td>0.50</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>0.225</td>\n",
       "      <td>0.112</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>110407 rows × 66 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         index      bloc  icustayid   charttime  gender       age  elixhauser  \\\n",
       "0            0  0.000000         11  6898241400     1.0  0.902277    0.461538   \n",
       "1            1  0.222560         11  6898255800     1.0  0.902277    0.461538   \n",
       "2            2  0.356608         11  6898270200     1.0  0.902277    0.461538   \n",
       "3            3  0.452837         11  6898284600     1.0  0.902277    0.461538   \n",
       "4            4  0.527957         11  6898299000     1.0  0.902277    0.461538   \n",
       "...        ...       ...        ...         ...     ...       ...         ...   \n",
       "110402  110402  0.923625      99984  6807758400     1.0  0.829460    0.230769   \n",
       "110403  110403  0.944365      99984  6807772800     1.0  0.829460    0.230769   \n",
       "110404  110404  0.963927      99984  6807787200     1.0  0.829460    0.230769   \n",
       "110405  110405  0.982436      99984  6807801600     1.0  0.829460    0.230769   \n",
       "110406  110406  1.000000      99984  6807816000     1.0  0.829460    0.230769   \n",
       "\n",
       "        re_admission  died_in_hosp  died_within_48h_of_out_time  ...  \\\n",
       "0                1.0           0.0                          0.0  ...   \n",
       "1                1.0           0.0                          0.0  ...   \n",
       "2                1.0           0.0                          0.0  ...   \n",
       "3                1.0           0.0                          0.0  ...   \n",
       "4                1.0           0.0                          0.0  ...   \n",
       "...              ...           ...                          ...  ...   \n",
       "110402           1.0           0.0                          0.0  ...   \n",
       "110403           1.0           0.0                          0.0  ...   \n",
       "110404           1.0           0.0                          0.0  ...   \n",
       "110405           1.0           0.0                          0.0  ...   \n",
       "110406           1.0           0.0                          0.0  ...   \n",
       "\n",
       "        output_4hourly  cumulated_balance      SOFA  SIRS  vaso_input  \\\n",
       "0             0.000000           0.392265  0.478261  0.00         0.0   \n",
       "1             0.718397           0.391715  0.391304  0.00         0.0   \n",
       "2             0.735149           0.391045  0.304348  0.25         0.0   \n",
       "3             0.738138           0.390351  0.347826  0.25         0.0   \n",
       "4             0.710650           0.389849  0.347826  0.25         0.0   \n",
       "...                ...                ...       ...   ...         ...   \n",
       "110402        0.747842           0.364055  0.217391  0.75         2.0   \n",
       "110403        0.770689           0.363038  0.217391  0.50         2.0   \n",
       "110404        0.742432           0.362308  0.304348  0.50         2.0   \n",
       "110405        0.723777           0.361722  0.304348  0.50         2.0   \n",
       "110406        0.734385           0.361058  0.347826  0.50         3.0   \n",
       "\n",
       "        iv_input  action     reward  max_dose_vaso_unnorm  abchange_vc  \n",
       "0            0.0       0   0.383136                 0.000        0.000  \n",
       "1            0.0       0  -0.271041                 0.000        0.000  \n",
       "2            0.0       0  -0.884898                 0.000        0.000  \n",
       "3            0.0       0  -0.025000                 0.000        0.000  \n",
       "4            0.0       0  -0.025000                 0.000        0.000  \n",
       "...          ...     ...        ...                   ...          ...  \n",
       "110402       0.0       2  -0.025000                 0.113        0.000  \n",
       "110403       0.0       2   1.740110                 0.113        0.000  \n",
       "110404       0.0       2   1.183736                 0.113        0.000  \n",
       "110405       0.0       2   0.634898                 0.113        0.000  \n",
       "110406       0.0       3  15.000000                 0.225        0.112  \n",
       "\n",
       "[110407 rows x 66 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.fillna(0)\n",
    "val_df.fillna(0)\n",
    "test_df.fillna(0)\n",
    "preg_df.fillna(0)\n",
    "control_1_df.fillna(0)\n",
    "control_2_df.fillna(0)\n",
    "old_df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,len(columns)):\n",
    "    val_df[columns[i]] = pd.to_numeric(val_df[columns[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_df = val_df.drop(\"elixhauser\", axis=1)\n",
    "# val_df = val_df.drop(\"died_in_hosp\", axis=1)\n",
    "# val_df = val_df.drop(\"delay_end_of_record_and_discharge_or_death\", axis=1)\n",
    "# val_df = val_df.drop(\"died_within_48h_of_out_time\", axis=1)\n",
    "# val_df = val_df.drop(\"Ionised_Ca\", axis=1)\n",
    "# val_df = val_df.drop(\"CO2_mEqL\", axis=1)\n",
    "# val_df = val_df.drop(\"Albumin\", axis=1)\n",
    "# val_df = val_df.drop(\"charttime\", axis=1)\n",
    "# list_of_nan = []\n",
    "# for i, row in val_df.iterrows():\n",
    "#     if pd.isnull(row[\"bloc\"]):\n",
    "#             #print(i)\n",
    "#         list_of_nan.append(i)\n",
    "#             #print(list_of_nan)\n",
    "# val_df = val_df.drop(list_of_nan)\n",
    "# val_df = val_df.fillna(0)\n",
    "# val_df.index = range(len(val_df))\n",
    "# ##################################################################\n",
    "# test_df = test_df.drop(\"elixhauser\", axis=1)\n",
    "# test_df = test_df.drop(\"died_in_hosp\", axis=1)\n",
    "# test_df = test_df.drop(\"delay_end_of_record_and_discharge_or_death\", axis=1)\n",
    "# test_df = test_df.drop(\"died_within_48h_of_out_time\", axis=1)\n",
    "# test_df = test_df.drop(\"Ionised_Ca\", axis=1)\n",
    "# test_df = test_df.drop(\"CO2_mEqL\", axis=1)\n",
    "# test_df = test_df.drop(\"Albumin\", axis=1)\n",
    "# test_df = test_df.drop(\"charttime\", axis=1)\n",
    "# list_of_nan = []\n",
    "# for i, row in test_df.iterrows():\n",
    "#     if pd.isnull(row[\"bloc\"]):\n",
    "#             #print(i)\n",
    "#         list_of_nan.append(i)\n",
    "#             #print(list_of_nan)\n",
    "# test_df = test_df.drop(list_of_nan)\n",
    "# test_df = test_df.fillna(0)\n",
    "# test_df.index = range(len(test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_preg = pd.read_csv('../Created Data/rl_pregnant_data_final_cont.csv')\n",
    "# df_preg = df_preg.drop(\"elixhauser\", axis=1)\n",
    "# df_preg = df_preg.drop(\"died_in_hosp\", axis=1)\n",
    "# df_preg = df_preg.drop(\"delay_end_of_record_and_discharge_or_death\", axis=1)\n",
    "# df_preg = df_preg.drop(\"died_within_48h_of_out_time\", axis=1)\n",
    "# df_preg = df_preg.drop(\"Ionised_Ca\", axis=1)\n",
    "# df_preg = df_preg.drop(\"CO2_mEqL\", axis=1)\n",
    "# df_preg = df_preg.drop(\"Albumin\", axis=1)\n",
    "# df_preg = df_preg.drop(\"charttime\", axis=1)\n",
    "# list_of_nan = []\n",
    "# for i, row in df_preg.iterrows():\n",
    "#     if pd.isnull(row[\"bloc\"]):\n",
    "#             #print(i)\n",
    "#         list_of_nan.append(i)\n",
    "#             #print(list_of_nan)\n",
    "# df_preg = df_preg.drop(list_of_nan)\n",
    "# df_preg = df_preg.fillna(0)\n",
    "# df_preg.index = range(len(df_preg))\n",
    "# ########################################################################################################################\n",
    "# df_cont = pd.read_csv('../Created Data/rl_control_data_final_cont.csv')\n",
    "# df_cont = df_cont.drop(\"elixhauser\", axis=1)\n",
    "# df_cont = df_cont.drop(\"died_in_hosp\", axis=1)\n",
    "# df_cont = df_cont.drop(\"delay_end_of_record_and_discharge_or_death\", axis=1)\n",
    "# df_cont = df_cont.drop(\"died_within_48h_of_out_time\", axis=1)\n",
    "# df_cont = df_cont.drop(\"Ionised_Ca\", axis=1)\n",
    "# df_cont = df_cont.drop(\"CO2_mEqL\", axis=1)\n",
    "# df_cont = df_cont.drop(\"Albumin\", axis=1)\n",
    "# df_cont = df_cont.drop(\"charttime\", axis=1)\n",
    "# list_of_nan = []\n",
    "# for i, row in df_cont.iterrows():\n",
    "#     if pd.isnull(row[\"bloc\"]):\n",
    "#             #print(i)\n",
    "#         list_of_nan.append(i)\n",
    "#             #print(list_of_nan)\n",
    "# df_cont = df_cont.drop(list_of_nan)\n",
    "# df_cont = df_cont.fillna(0)\n",
    "# df_cont.index = range(len(df_cont))\n",
    "# #########################################################################################################################\n",
    "# df_cont_sec = pd.read_csv('../Created Data/rl_control_sec_data_final_cont.csv')\n",
    "# df_cont_sec = df_cont_sec.drop(\"elixhauser\", axis=1)\n",
    "# df_cont_sec = df_cont_sec.drop(\"died_in_hosp\", axis=1)\n",
    "# df_cont_sec = df_cont_sec.drop(\"delay_end_of_record_and_discharge_or_death\", axis=1)\n",
    "# df_cont_sec = df_cont_sec.drop(\"died_within_48h_of_out_time\", axis=1)\n",
    "# df_cont_sec = df_cont_sec.drop(\"Ionised_Ca\", axis=1)\n",
    "# df_cont_sec = df_cont_sec.drop(\"CO2_mEqL\", axis=1)\n",
    "# df_cont_sec = df_cont_sec.drop(\"Albumin\", axis=1)\n",
    "# df_cont_sec = df_cont_sec.drop(\"charttime\", axis=1)\n",
    "# list_of_nan = []\n",
    "# for i, row in df_cont_sec.iterrows():\n",
    "#     if pd.isnull(row[\"bloc\"]):\n",
    "#             #print(i)\n",
    "#         list_of_nan.append(i)\n",
    "#             #print(list_of_nan)\n",
    "# df_cont_sec = df_cont_sec.drop(list_of_nan)\n",
    "# df_cont_sec = df_cont_sec.fillna(0)\n",
    "# df_cont_sec.index = range(len(df_cont_sec))\n",
    "# #########################################################################################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_old = pd.read_csv('../Created Data/rl_old_data_final_cont.csv')\n",
    "# df_old = df_old.drop(\"elixhauser\", axis=1)\n",
    "# df_old = df_old.drop(\"died_in_hosp\", axis=1)\n",
    "# df_old = df_old.drop(\"delay_end_of_record_and_discharge_or_death\", axis=1)\n",
    "# df_old = df_old.drop(\"died_within_48h_of_out_time\", axis=1)\n",
    "# df_old = df_old.drop(\"Ionised_Ca\", axis=1)\n",
    "# df_old = df_old.drop(\"CO2_mEqL\", axis=1)\n",
    "# df_old = df_old.drop(\"Albumin\", axis=1)\n",
    "# df_old = df_old.drop(\"charttime\", axis=1)\n",
    "# list_of_nan = []\n",
    "# for i, row in df_old.iterrows():\n",
    "#     if pd.isnull(row[\"bloc\"]):\n",
    "#             #print(i)\n",
    "#         list_of_nan.append(i)\n",
    "#             #print(list_of_nan)\n",
    "# df_old = df_old.drop(list_of_nan)\n",
    "# df_old = df_old.fillna(0)\n",
    "# df_old.index = range(len(df_old))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_old.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "REWARD_THRESHOLD = 20\n",
    "reg_lambda = 5\n",
    "reg_lambda2 = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PER important weights and params\n",
    "per_flag = True\n",
    "beta_start = 0.9\n",
    "df['prob'] = abs(df['reward'])\n",
    "temp = 1.0/df['prob']\n",
    "#temp[temp == float('Inf')] = 1.0\n",
    "df['imp_weight'] = pow((1.0/len(df) * temp), beta_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SET THIS TO FALSE\n",
    "clip_reward = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_dose_map = {0: 0, 1: 0.04, 2: 0.135, 3: 0.27, 4:0.7859999999999999, 5: 0, 6: 0.04, 7: 0.135, 8:0.27, 9:0.7859999999999999, 10: 0, 11:0.04, 12: 0.135, 13:0.27, 14:0.7859999999999999, 15:0, 16:0.04, 17:0.135, 18:0.27, 19:0.7859999999999999, 20:0, 21:0.04, 22: 0.135, 23:0.27, 24: 0.7859999999999999}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_1_size = 128\n",
    "hidden_2_size = 128\n",
    "#  Q-network uses Leaky ReLU activation\n",
    "class Qnetwork():\n",
    "    def __init__(self):\n",
    "        self.phase = tf.placeholder(tf.bool)\n",
    "\n",
    "        self.num_actions = 25\n",
    "\n",
    "        self.input_size = len(state_features)\n",
    "\n",
    "        self.state = tf.placeholder(tf.float32, shape=[None, self.input_size],name=\"input_state\")\n",
    "\n",
    "        self.fc_1 = tf.contrib.layers.fully_connected(self.state, hidden_1_size, activation_fn=None)\n",
    "        self.fc_1_bn = tf.contrib.layers.batch_norm(self.fc_1, center=True, scale=True, is_training=self.phase)\n",
    "        self.fc_1_ac = tf.maximum(self.fc_1_bn, self.fc_1_bn*0.01)\n",
    "        self.fc_2 = tf.contrib.layers.fully_connected(self.fc_1_ac, hidden_2_size, activation_fn=None)\n",
    "        self.fc_2_bn = tf.contrib.layers.batch_norm(self.fc_2, center=True, scale=True, is_training=self.phase)\n",
    "        self.fc_2_ac = tf.maximum(self.fc_2_bn, self.fc_2_bn*0.01)\n",
    "        \n",
    "        # advantage and value streams\n",
    "        self.streamA,self.streamV = tf.split(self.fc_2_ac,2,axis=1)\n",
    "        self.AW = tf.Variable(tf.random_normal([hidden_2_size//2,self.num_actions]))\n",
    "        self.VW = tf.Variable(tf.random_normal([hidden_2_size//2,1]))\n",
    "        self.Advantage = tf.matmul(self.streamA,self.AW)\n",
    "        self.Value = tf.matmul(self.streamV,self.VW)\n",
    "        \n",
    "        #Then combine them together to get our final Q-values.\n",
    "        self.q_output = self.Value + tf.subtract(self.Advantage,tf.reduce_mean(self.Advantage,axis=1,keep_dims=True))\n",
    "       \n",
    "        self.predict = tf.argmax(self.q_output,1, name='predict') # vector of length batch size\n",
    "        \n",
    "        #Below we obtain the loss by taking the sum of squares difference between the target and predicted Q values.\n",
    "        self.targetQ = tf.placeholder(shape=[None],dtype=tf.float32)\n",
    "        self.actions = tf.placeholder(shape=[None],dtype=tf.int32)\n",
    "        self.actions_onehot = tf.one_hot(self.actions,self.num_actions,dtype=tf.float32)\n",
    "        \n",
    "        # Importance sampling weights for PER, used in network update         \n",
    "        self.imp_weights = tf.placeholder(shape=[None], dtype=tf.float32)\n",
    "        \n",
    "        # select the Q values for the actions that would be selected         \n",
    "        self.Q = tf.reduce_sum(tf.multiply(self.q_output, self.actions_onehot), reduction_indices=1) # batch size x 1 vector\n",
    "        \n",
    "        \n",
    "        # regularisation penalises the network when it produces rewards that are above the\n",
    "        # reward threshold, to ensure reasonable Q-value predictions       \n",
    "        self.reg_vector = tf.maximum(tf.abs(self.Q)-REWARD_THRESHOLD,0)\n",
    "        self.reg_term = tf.reduce_sum(self.reg_vector)\n",
    "        \n",
    "        \n",
    "        ############## second regularisation term ###################################\n",
    "        \n",
    "        self.pre_vasodose = tf.exp(self.state[:,3])- 0.1 -self.state[:,47]\n",
    "        \n",
    "        self.cur_vasodose = tf.placeholder(shape=[None],dtype=tf.float32)\n",
    "        \n",
    "        #self.cur_vasodose = np.array([action_dose_map[i] for i in self.predict], dtype= np.float32)\n",
    "        self.tf_abchange = tf.minimum(tf.abs(tf.subtract(self.cur_vasodose, self.pre_vasodose)), 0.785)\n",
    "        \n",
    "        self.reg_vector2 = tf.where(self.tf_abchange >= 0.785, tf.ones_like(self.tf_abchange), tf.zeros_like(self.tf_abchange)) # shape=(?,)\n",
    "        self.reg_term2 = tf.reduce_sum(self.reg_vector2)\n",
    "        \n",
    "        \n",
    "        ##############################################################################\n",
    "        \n",
    "        self.abs_error = tf.abs(self.targetQ - self.Q)\n",
    "        \n",
    "        self.td_error = tf.square(self.targetQ - self.Q)\n",
    "        \n",
    "        # below is the loss when we are not using PER\n",
    "        self.old_loss = tf.reduce_mean(self.td_error)\n",
    "        \n",
    "        # as in the paper, to get PER loss we weight the squared error by the importance weights\n",
    "        self.per_error = tf.multiply(self.td_error, self.imp_weights)\n",
    "\n",
    "        # total loss is a sum of PER loss and the regularisation term\n",
    "        if per_flag:\n",
    "            self.loss = tf.reduce_mean(self.per_error) + reg_lambda*self.reg_term + reg_lambda2*self.reg_term2\n",
    "        else:\n",
    "            self.loss = self.old_loss + reg_lambda*self.reg_term\n",
    "\n",
    "        self.trainer = tf.train.AdamOptimizer(learning_rate=0.0001)\n",
    "        self.update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "        with tf.control_dependencies(self.update_ops):\n",
    "        # Ensures that we execute the update_ops before performing the model update, so batchnorm works\n",
    "            self.update_model = self.trainer.minimize(self.loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function is needed to update parameters between main and target network\n",
    "# tf_vars are the trainable variables to update, and tau is the rate at which to update\n",
    "# returns tf ops corresponding to the updates\n",
    "def update_target_graph(tf_vars,tau):\n",
    "    total_vars = len(tf_vars)\n",
    "    op_holder = []\n",
    "    for idx,var in enumerate(tf_vars[0:int(total_vars/2)]):\n",
    "        op_holder.append(tf_vars[idx+int(total_vars/2)].assign((var.value()*tau) + ((1-tau)*tf_vars[idx+int(total_vars/2)].value())))\n",
    "    return op_holder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_target(op_holder,sess):\n",
    "    for op in op_holder:\n",
    "        sess.run(op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_train_batch(size):\n",
    "    if per_flag:\n",
    "        # uses prioritised exp replay\n",
    "        a = df.sample(n=size, weights=df['prob'])\n",
    "    else:\n",
    "        a = df.sample(n=size)\n",
    "    states = None\n",
    "    actions = None\n",
    "    rewards = None\n",
    "    next_states = None\n",
    "    done_flags = None\n",
    "    for i in a.index:\n",
    "        cur_state = a.loc[i,state_features]\n",
    "        #iv = int(a.ix[i, 'iv_input'])\n",
    "        #vaso = int(a.ix[i, 'vaso_input'])\n",
    "        #action = action_map[iv,vaso]\n",
    "        action = int(a.loc[i, 'action'])\n",
    "        reward = a.loc[i,'reward']\n",
    "        \n",
    "        if clip_reward:\n",
    "            if reward > 1: reward = 1\n",
    "            if reward < -1: reward = -1\n",
    "\n",
    "        if i != df.index[-1]:\n",
    "            # if not terminal step in trajectory             \n",
    "            if df.loc[i, 'icustayid'] == df.loc[i+1, 'icustayid']:\n",
    "                next_state = df.loc[i + 1, state_features]\n",
    "                done = 0\n",
    "            else:\n",
    "                # trajectory is finished\n",
    "                next_state = np.zeros(len(cur_state))\n",
    "                done = 1\n",
    "        else:\n",
    "            # last entry in df is the final state of that trajectory\n",
    "            next_state = np.zeros(len(cur_state))\n",
    "            done = 1\n",
    "\n",
    "        if states is None:\n",
    "            states = copy.deepcopy(cur_state)\n",
    "        else:\n",
    "            states = np.vstack((states,cur_state))\n",
    "\n",
    "        if actions is None:\n",
    "            actions = [action]\n",
    "        else:\n",
    "            actions = np.vstack((actions,action))\n",
    "        \n",
    "        if rewards is None:\n",
    "            rewards = [reward]\n",
    "        else:\n",
    "            rewards = np.vstack((rewards,reward))\n",
    "\n",
    "        if next_states is None:\n",
    "            next_states = copy.deepcopy(next_state)\n",
    "        else:\n",
    "            next_states = np.vstack((next_states,next_state))\n",
    "\n",
    "        if done_flags is None:\n",
    "            done_flags = [done]\n",
    "        else:\n",
    "            done_flags = np.vstack((done_flags,done))\n",
    "    \n",
    "    return (states, np.squeeze(actions), np.squeeze(rewards), next_states, np.squeeze(done_flags), a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract chunks of length size from the relevant dataframe, and yield these to the caller\n",
    "def process_eval_batch(size, eval_type = None):\n",
    "    if eval_type is None:\n",
    "        raise Exception('Provide eval_type to process_eval_batch')\n",
    "    elif eval_type == 'train':\n",
    "        a = df.copy()\n",
    "    elif eval_type == 'val':\n",
    "        a = val_df.copy()\n",
    "    elif eval_type == 'test':\n",
    "        a = test_df.copy()\n",
    "    elif eval_type == 'pregnant':\n",
    "        a = preg_df.copy()\n",
    "    elif eval_type == 'control':\n",
    "        a = control_1_df.copy()\n",
    "    elif eval_type == 'control_sec':\n",
    "        a = control_2_df.copy()\n",
    "    elif eval_type == 'old':\n",
    "        a = old_df.copy()\n",
    "    else:\n",
    "        raise Exception('Unknown eval_type')\n",
    "    count = 0\n",
    "    while count < len(a.index):\n",
    "       # print(count, len(a.index))\n",
    "        states = None\n",
    "        actions = None\n",
    "        rewards = None\n",
    "        next_states = None\n",
    "        done_flags = None\n",
    "\n",
    "        start_idx = count\n",
    "        end_idx = min(len(a.index), count+size)\n",
    "        segment = a.index[start_idx:end_idx]\n",
    "        \n",
    "        for i in segment:\n",
    "            cur_state = a.loc[i,state_features]\n",
    "            #iv = int(a.ix[i, 'iv_input'])\n",
    "            #vaso = int(a.ix[i, 'vaso_input'])\n",
    "            #action = action_map[iv,vaso]\n",
    "            action = int(a.loc[i,'action'])\n",
    "            reward = a.loc[i,'reward']\n",
    "            \n",
    "            if clip_reward:\n",
    "                if reward > 1: reward = 1\n",
    "                if reward < -1: reward = -1\n",
    "\n",
    "            if i != a.index[-1]:\n",
    "                # if not terminal step in trajectory             \n",
    "                if a.loc[i, 'icustayid'] == a.loc[i+1, 'icustayid']:\n",
    "                    next_state = a.loc[i + 1, state_features]\n",
    "                    done = 0\n",
    "                else:\n",
    "                    # trajectory is finished\n",
    "                    next_state = np.zeros(len(cur_state))\n",
    "                    done = 1\n",
    "            else:\n",
    "                # last entry in df is the final state of that trajectory\n",
    "                next_state = np.zeros(len(cur_state))\n",
    "                done = 1\n",
    "\n",
    "            if states is None:\n",
    "                states = copy.deepcopy(cur_state)\n",
    "            else:\n",
    "                states = np.vstack((states,cur_state))\n",
    "\n",
    "            if actions is None:\n",
    "                actions = [action]\n",
    "            else:\n",
    "                actions = np.vstack((actions,action))\n",
    "\n",
    "            if rewards is None:\n",
    "                rewards = [reward]\n",
    "            else:\n",
    "                rewards = np.vstack((rewards,reward))\n",
    "\n",
    "            if next_states is None:\n",
    "                next_states = copy.deepcopy(next_state)\n",
    "            else:\n",
    "                next_states = np.vstack((next_states,next_state))\n",
    "\n",
    "            if done_flags is None:\n",
    "                done_flags = [done]\n",
    "            else:\n",
    "                done_flags = np.vstack((done_flags,done))\n",
    "\n",
    "        yield (states, np.squeeze(actions), np.squeeze(rewards), next_states, np.squeeze(done_flags), a)\n",
    "        \n",
    "        count += size\n",
    "       # if count >= 3000:\n",
    "       #     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_eval(eval_type):\n",
    "    gen = process_eval_batch(size = 1000, eval_type=eval_type)\n",
    "\n",
    "    phys_q_ret = []\n",
    "    actions_ret = []\n",
    "    agent_q_ret = []\n",
    "    actions_taken_ret = []\n",
    "    error_ret = 0\n",
    "  \n",
    "\n",
    "    for b in gen:\n",
    "        \n",
    "        states,actions,rewards,next_states, done_flags, _ = b\n",
    "\n",
    "        # firstly get the chosen actions at the next timestep\n",
    "        actions_from_q1 = sess.run(mainQN.predict,feed_dict={mainQN.state:next_states, mainQN.phase : 0})\n",
    "\n",
    "        # Q values for the next timestep from target network, as part of the Double DQN update\n",
    "        Q2 = sess.run(targetQN.q_output,feed_dict={targetQN.state:next_states, targetQN.phase : 0})\n",
    "\n",
    "        # handles the case when a trajectory is finished\n",
    "        end_multiplier = 1 - done_flags\n",
    "\n",
    "        # target Q value using Q values from target, and actions from main\n",
    "        double_q_value = Q2[range(len(Q2)),actions_from_q1]\n",
    "\n",
    "        # definition of target Q\n",
    "        targetQ = rewards + (gamma*double_q_value * end_multiplier)\n",
    "\n",
    "        # get the output q's, actions, and loss\n",
    "        q_output,actions_taken, abs_error = sess.run([mainQN.q_output,mainQN.predict, mainQN.abs_error], \\\n",
    "            feed_dict={mainQN.state:states,\n",
    "                       mainQN.targetQ:targetQ, \n",
    "                       mainQN.actions:actions,\n",
    "                       mainQN.phase:False})\n",
    "        #print(actions_taken)\n",
    "       # actions_taken=actions_taken-1\n",
    "        # return the relevant q values and actions\n",
    "        phys_q = q_output[range(len(q_output)), actions]\n",
    "        agent_q = q_output[range(len(q_output)), actions_taken]\n",
    "        error = np.mean(abs_error)\n",
    "        #print(actions_taken)\n",
    "#       update the return vals\n",
    "        phys_q_ret.extend(phys_q)\n",
    "        \n",
    "        \n",
    "        actions_ret.extend(actions)        \n",
    "        agent_q_ret.extend(agent_q)\n",
    "        actions_taken_ret.extend(actions_taken)\n",
    "        error_ret += error\n",
    "\n",
    "    #print(actions_taken_ret)\n",
    "    return phys_q_ret, actions_ret, agent_q_ret, actions_taken_ret, error_ret\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Used to run diagnostics on the train set\n",
    "phys_q_train = []\n",
    "agent_q_train = []\n",
    "phys_actions_tr = []\n",
    "agent_actions_tr = []\n",
    "def train_set_performance():\n",
    "    count = 0\n",
    "    global phys_q_train\n",
    "    global agent_q_train\n",
    "    global phys_actions\n",
    "    global agent_actions\n",
    "    phys_q_train = []\n",
    "    agent_q_train = []\n",
    "    phys_actions_tr = []\n",
    "    agent_actions_tr = []\n",
    "    for r in df.index:\n",
    "        cur_state = [df.loc[r,state_features]]\n",
    "        #iv = int(df.ix[r, 'iv_input'])\n",
    "        #vaso = int(df.ix[r, 'vaso_input'])\n",
    "        #action = action_map[iv,vaso]\n",
    "        action = int(df.loc[r,'action'])\n",
    "        output_q = np.squeeze(sess.run(mainQN.q_output, feed_dict = {mainQN.state : cur_state, mainQN.phase : False}))\n",
    "        phys_q_train.append(output_q[action])\n",
    "        agent_q_train.append(max(output_q))\n",
    "        agent_actions_tr.append(np.argmax(output_q))\n",
    "        phys_actions_tr.append(action)\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True  # Don't use all GPUs \n",
    "config.allow_soft_placement = True  # Enable manual control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_save_results():\n",
    "    # get the chosen actions for the train, val, and test set when training is complete.\n",
    "    _, _, agent_q_train, agent_actions_train, _ = do_eval(eval_type = 'train')\n",
    "    print (\"length IS \", len(agent_actions_train))\n",
    "    with open(save_dir + 'dqn_normal_actions_train.p', 'wb') as f:\n",
    "        pickle.dump(agent_actions_train, f)\n",
    "    _, _, agent_q_val, agent_actions_val, _ = do_eval(eval_type = 'val')        \n",
    "    _, _, agent_q_test, agent_actions_test, _ = do_eval(eval_type = 'test')   \n",
    "    _, _, agent_q_preg, agent_actions_preg, _ = do_eval(eval_type = 'pregnant')\n",
    "    _, _, agent_q_control, agent_actions_control, _ = do_eval(eval_type = 'control')\n",
    "    _, _, agent_q_old, agent_actions_old, _ = do_eval(eval_type = 'old')\n",
    "    _, _, agent_q_control_sec, agent_actions_control_sec, _ = do_eval(eval_type = 'control_sec')\n",
    "    \n",
    "    # save everything for later - they're used in policy evaluation and when generating plots\n",
    "    with open(save_dir + 'dqn_normal_actions_train.p', 'wb') as f:\n",
    "        pickle.dump(agent_actions_train, f)\n",
    "    with open(save_dir + 'dqn_normal_actions_val.p', 'wb') as f:\n",
    "        pickle.dump(agent_actions_val, f)\n",
    "    with open(save_dir + 'dqn_normal_actions_test.p', 'wb') as f:\n",
    "        pickle.dump(agent_actions_test, f)\n",
    "    with open(save_dir + 'dqn_normal_actions_preg.p', 'wb') as f:\n",
    "        pickle.dump(agent_actions_preg, f)\n",
    "    with open(save_dir + 'dqn_normal_actions_cont.p', 'wb') as f:\n",
    "        pickle.dump(agent_actions_control, f)\n",
    "    with open(save_dir + 'dqn_normal_actions_old.p', 'wb') as f:\n",
    "        pickle.dump(agent_actions_old, f)\n",
    "    with open(save_dir + 'dqn_normal_actions_cont_sec.p', 'wb') as f:\n",
    "        pickle.dump(agent_actions_control_sec, f)\n",
    "        \n",
    "    with open(save_dir + 'dqn_normal_q_train.p', 'wb') as f:\n",
    "        pickle.dump(agent_q_train, f)\n",
    "    with open(save_dir + 'dqn_normal_q_val.p', 'wb') as f:\n",
    "        pickle.dump(agent_q_val, f)\n",
    "    with open(save_dir + 'dqn_normal_q_test.p', 'wb') as f:\n",
    "        pickle.dump(agent_q_test, f)\n",
    "    with open(save_dir + 'dqn_normal_q_preg.p', 'wb') as f:\n",
    "        pickle.dump(agent_q_preg, f)\n",
    "    with open(save_dir + 'dqn_normal_q_cont.p', 'wb') as f:\n",
    "        pickle.dump(agent_q_control, f)\n",
    "    with open(save_dir + 'dqn_normal_q_old.p', 'wb') as f:\n",
    "        pickle.dump(agent_q_old, f)\n",
    "    with open(save_dir + 'dqn_normal_q_cont_sec.p', 'wb') as f:\n",
    "        pickle.dump(agent_q_control_sec, f)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_final_save_results():\n",
    "    # get the chosen actions for the train, val, and test set when training is complete.\n",
    "    _, _, agent_q_train, agent_actions_train, _ = do_eval(eval_type = 'train')\n",
    "    print (\"length IS \", len(agent_actions_train))\n",
    "    with open(save_dir + 'dqn_normal_actions_train.p', 'wb') as f:\n",
    "        pickle.dump(agent_actions_train, f)\n",
    "    _, _, agent_q_val, agent_actions_val, _ = do_eval(eval_type = 'val')        \n",
    "    _, _, agent_q_test, agent_actions_test, _ = do_eval(eval_type = 'test')   \n",
    "    _, _, agent_q_preg, agent_actions_preg, _ = do_eval(eval_type = 'pregnant')\n",
    "    _, _, agent_q_control, agent_actions_control, _ = do_eval(eval_type = 'control')\n",
    "    _, _, agent_q_old, agent_actions_old, _ = do_eval(eval_type = 'old')\n",
    "    _, _, agent_q_control_sec, agent_actions_control_sec, _ = do_eval(eval_type = 'control_sec')\n",
    "    \n",
    "    # save everything for later - they're used in policy evaluation and when generating plots\n",
    "    with open(save_dir + 'dqn_normal_actions_train.p', 'wb') as f:\n",
    "        pickle.dump(agent_actions_train, f)\n",
    "    with open(save_dir + 'dqn_normal_actions_val.p', 'wb') as f:\n",
    "        pickle.dump(agent_actions_val, f)\n",
    "    with open(save_dir + 'dqn_normal_actions_test.p', 'wb') as f:\n",
    "        pickle.dump(agent_actions_test, f)\n",
    "    with open(save_dir + 'dqn_normal_actions_preg.p', 'wb') as f:\n",
    "        pickle.dump(agent_actions_preg, f)\n",
    "    with open(save_dir + 'dqn_normal_actions_cont.p', 'wb') as f:\n",
    "        pickle.dump(agent_actions_control, f)\n",
    "    with open(save_dir + 'dqn_normal_actions_old.p', 'wb') as f:\n",
    "        pickle.dump(agent_actions_old, f)\n",
    "    with open(save_dir + 'dqn_normal_actions_cont_sec.p', 'wb') as f:\n",
    "        pickle.dump(agent_actions_control_sec, f)\n",
    "        \n",
    "    with open(save_dir + 'dqn_normal_q_train.p', 'wb') as f:\n",
    "        pickle.dump(agent_q_train, f)\n",
    "    with open(save_dir + 'dqn_normal_q_val.p', 'wb') as f:\n",
    "        pickle.dump(agent_q_val, f)\n",
    "    with open(save_dir + 'dqn_normal_q_test.p', 'wb') as f:\n",
    "        pickle.dump(agent_q_test, f)\n",
    "    with open(save_dir + 'dqn_normal_q_preg.p', 'wb') as f:\n",
    "        pickle.dump(agent_q_preg, f)\n",
    "    with open(save_dir + 'dqn_normal_q_cont.p', 'wb') as f:\n",
    "        pickle.dump(agent_q_control, f)\n",
    "    with open(save_dir + 'dqn_normal_q_old.p', 'wb') as f:\n",
    "        pickle.dump(agent_q_old, f)\n",
    "    with open(save_dir + 'dqn_normal_q_cont-sec.p', 'wb') as f:\n",
    "        pickle.dump(agent_q_control_sec, f)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001AF06EA4080>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001AF06EA4080>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001AF06EA4080>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001AF06EA4080>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001AF06EA4588>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001AF06EA4588>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001AF06EA4588>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001AF06EA4588>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING:tensorflow:From <ipython-input-23-aef4fca161a0>:60: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001AF08E65EB8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001AF08E65EB8>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001AF08E65EB8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001AF08E65EB8>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001AF09290828>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001AF09290828>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001AF09290828>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001AF09290828>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "Running default init\n",
      "Init done\n",
      "Saved Model, step is 1000\n",
      "Average loss is  11.52048255498323\n",
      "Saving PER and importance weights\n",
      "physactions  [ 5  0  0  5 24  0  0  0 20  0 10 22 15  6  0 15  0  0 15 22  0  0 15 15\n",
      "  5 20 23  0  0  6  0  0]\n",
      "chosen actions  [11  9 22 20  2 11  2  2 16  2  2 16 16  2 22 20 16  2  2 22 11 22 22  4\n",
      " 20  2  2 16 10 24  2 15]\n",
      "2.2874255180358887\n",
      "-0.037444152\n",
      "2.4358132\n",
      "Saved Model, step is 2000\n",
      "Average loss is  10.893936020967784\n",
      "Saving PER and importance weights\n",
      "physactions  [12  0 20 18 15 20  5 12  5  5 20 20  5  5 10  0  5 15  0  0 15 15  5 16\n",
      "  5  0  0 15  5 10  5  0]\n",
      "chosen actions  [ 2  3  2  4  8 11  2  2  4 20 20 19  2 20 20  2  2  2  9  2 20 18 22  2\n",
      " 22 22 11 22  2 20  4 22]\n",
      "2.6810284729661613\n",
      "1.2700479\n",
      "4.741601\n",
      "Saved Model, step is 3000\n",
      "Average loss is  11.216730427097529\n",
      "Saving PER and importance weights\n",
      "physactions  [10  0  0  0  5  0 15  1 10  5 20  6  0  0 19 15 20 17  0 10  0  0  5 15\n",
      "  0  5  0  5  0 20 22  5]\n",
      "chosen actions  [21 22 20 21 22 22 20  2 16 21  2 21  2 22  2  2  8 13 22 20 22 22  8 11\n",
      " 22 18 19  5  2 16  2  4]\n",
      "3.252827364822914\n",
      "1.7764299\n",
      "6.3724737\n",
      "Saved Model, step is 4000\n",
      "Average loss is  10.888562741702422\n",
      "Saving PER and importance weights\n",
      "physactions  [ 0 15 15 10  0 10  0 20 10 15 15  5  0  0  0 15 15  5  0 15  0 15  0  5\n",
      " 16  0  0 21 19  0 10  5]\n",
      "chosen actions  [ 2 20  2 18 16 20 22  2  2 22  2 20 11 22 12 19 21  2 11 20 22 22  4 16\n",
      " 18 21  2  2 20  6  2  2]\n",
      "3.76915665330558\n",
      "1.8365629\n",
      "7.730238\n",
      "Saved Model, step is 5000\n",
      "Average loss is  10.435772067779675\n",
      "Saving PER and importance weights\n",
      "physactions  [ 0 20 20  5  0 15 10 15  0  5 19 13 15 15 10 10  5 10 10 15 10  5 18 10\n",
      " 15 20 10  5 20 23 10 20]\n",
      "chosen actions  [22  2 16  2  2  3  2 21  3 10  2  2  3 20  8 21 22  2 22 20 12 22 24 21\n",
      " 12 22  2 20 12  2  4  2]\n",
      "4.332735752237254\n",
      "2.647567\n",
      "9.62111\n",
      "Saving results\n",
      "length IS  195421\n",
      "Saved Model, step is 6000\n",
      "Average loss is  9.924075982687064\n",
      "Saving PER and importance weights\n",
      "physactions  [ 7  5 10 14 15  0 15 24  6  0 20 15  0  0  0  0 23 10  0 10 11  5  0  0\n",
      " 20 20 15 20  0 15 20 10]\n",
      "chosen actions  [22 19  2  2  2 22 21 22 22  2 21  2 16 22 22 16  1  2 16  4  2 21  4  8\n",
      " 20  2  8  2  4 20  2  2]\n",
      "4.600989933671622\n",
      "2.8965752\n",
      "10.5344305\n",
      "Saved Model, step is 7000\n",
      "Average loss is  9.556187555018813\n",
      "Saving PER and importance weights\n",
      "physactions  [10 10  0 15  5 20  0 20 20  0 10  5 20 10 22  5 24  0  0  0 10 10 20  0\n",
      " 15  0  0 14 10 15 20 10]\n",
      "chosen actions  [ 2 20  4  1  3  8 22 22 19 22  2 12  2  8  2 22 20 22 10  3 18  8  2 20\n",
      " 15 16  2 22  2  2  2 22]\n",
      "4.950487317710087\n",
      "4.0733514\n",
      "11.636229\n",
      "Saved Model, step is 8000\n",
      "Average loss is  9.006806130647659\n",
      "Saving PER and importance weights\n",
      "physactions  [ 5  0 20  5  0  0  0  7  5 16  0 10  5 23  5 10  5 23  5 10 20 15 23 10\n",
      " 20 15 18  5  5  0  5  5]\n",
      "chosen actions  [ 4 20 21 22 22 22  4 19  2 22  5 20 19  2 21 20  2 22  4  2  2 22  2  2\n",
      "  2  2  2 21 11 22 16 22]\n",
      "4.957533984348692\n",
      "3.8834546\n",
      "11.194877\n",
      "Saved Model, step is 9000\n",
      "Average loss is  8.572019177680835\n",
      "Saving PER and importance weights\n",
      "physactions  [ 5  5 10 13  5  0 20 20  0  0  0 15  0  5 20 16  0 20 20 15 13  5  0 19\n",
      " 10  5  5 10  0  0  0 15]\n",
      "chosen actions  [21 11 22  2  2  2  8  2 22 16 22  2  3  2  2  2  0  2 20 22 16 20 22  2\n",
      "  2 16  9 21 21  4 20  2]\n",
      "5.018976935024919\n",
      "4.044059\n",
      "10.767506\n",
      "Saved Model, step is 10000\n",
      "Average loss is  8.492109828972257\n",
      "Saving PER and importance weights\n",
      "physactions  [ 0 20 23  5  5 10 10  0  5  0  5  0 10 21  5  0 15 15 15  0  5 20  0  0\n",
      " 15  5 15 10  5 20  0  0]\n",
      "chosen actions  [22  2  2 22  2 24  2 22  2 22 20 19  2  9 19 10 21 22  8 10  2  2  9  9\n",
      "  4 22  2  2  4  2 13  9]\n",
      "4.667995321339574\n",
      "4.1802855\n",
      "11.19097\n",
      "Saving results\n",
      "length IS  195421\n",
      "Saved Model, step is 11000\n",
      "Average loss is  8.345693043120205\n",
      "Saving PER and importance weights\n",
      "physactions  [ 5  0 23  0  5 10  5 20 15  0  5  5  0 10 10  0 23 17 16 17  0 15  0 19\n",
      "  0 10  5  0  0  5  0  0]\n",
      "chosen actions  [ 9 22  2 11 20 21 20 19  2  3 20  8  2  2 21 11 19  2 22  4  2 20 13  2\n",
      " 22  3  8  4  0  2 11 22]\n",
      "4.546565565569647\n",
      "4.1544414\n",
      "10.549371\n",
      "Saved Model, step is 12000\n",
      "Average loss is  8.008526082091034\n",
      "Saving PER and importance weights\n",
      "physactions  [ 0  0  0  0 15 20 21  0 15 10  5 20 24 15 20 15  0 20 21 15 10 12  4  0\n",
      "  6  5 23 15  5  5  4 10]\n",
      "chosen actions  [21 22 20  0 23 10 16 16  8  2  9  2 22  3 20 16  2  8  2  2 23  2 22  2\n",
      "  2  8  1 23  2 21 22  2]\n",
      "4.60308731013331\n",
      "4.437357\n",
      "10.688313\n",
      "Saved Model, step is 13000\n",
      "Average loss is  7.572299121888355\n",
      "Saving PER and importance weights\n",
      "physactions  [ 0  0 20  5  6  0 15  0  0  0  5  5 10 23  5 15  0  0  0  0  0  5  5  5\n",
      " 20  0  5  0  5  5  5 23]\n",
      "chosen actions  [22 12 21 20  3  2  2  4  7 22 22 18 20  2 22  2 11 12 22  2  4 13  2 12\n",
      " 16  3 22 20 21  2 20  2]\n",
      "4.968744113527495\n",
      "4.7079496\n",
      "10.746444\n",
      "Saved Model, step is 14000\n",
      "Average loss is  7.244607175240293\n",
      "Saving PER and importance weights\n",
      "physactions  [ 0  0  2 20  5  5 10  0  0  0  0 15 15 18 18  0 15 23 15 20  0  5  5 10\n",
      "  0  5  0 20 15 20 23 15]\n",
      "chosen actions  [ 0 22 11  2 11  3  2  0  3 12  0  2  9 16  2 16  5 22 21  8 11 20  2  2\n",
      " 22 21  2 20 19 20  2 20]\n",
      "5.661327312732565\n",
      "5.8608274\n",
      "11.7961445\n",
      "Saved Model, step is 15000\n",
      "Average loss is  6.959014829665422\n",
      "Saving PER and importance weights\n",
      "physactions  [15 16 10 22 10  5 20 20 15  5  1 15  5  5 15 10 20 21 15 15  0 15 21 10\n",
      " 16 20 10 20 15  0  5 20]\n",
      "chosen actions  [24  2 12  2  2  0  2  2  2 22 11  2  2  2 23 22 13 21 20 10 22  8 21 22\n",
      " 20  3 22  3 21  4  6 16]\n",
      "6.386723386830297\n",
      "7.200678\n",
      "12.763878\n",
      "Saving results\n",
      "length IS  195421\n",
      "Saved Model, step is 16000\n",
      "Average loss is  6.85071994327195\n",
      "Saving PER and importance weights\n",
      "physactions  [13 23 23 24 21 20  0  0  5  5  0 15 19  8  0 15  1  9 20 20 19 21 15 20\n",
      "  5  0 15  0 15  5 10  5]\n",
      "chosen actions  [18 10 23  2 12  3 21 22 22 20 22  2  2 22  0  3  0  4  2  3  2 15  0 19\n",
      "  2 22 19 22 19  2 16  2]\n",
      "6.2172761949999575\n",
      "7.3758464\n",
      "12.457534\n",
      "Saved Model, step is 17000\n",
      "Average loss is  7.149995471624657\n",
      "Saving PER and importance weights\n",
      "physactions  [10  0  0  0  0 15  4 10  2  0 10  5 10  0  6 15 10  0  0  0 15  8 15  5\n",
      "  5 10 10  0  8 15 20  5]\n",
      "chosen actions  [21  3  4 16  0 19 20  2 11 22 22 22 16  2  2 19 23  9  3 22 21 10 16 20\n",
      "  3  4  2 19  2  2  2  2]\n",
      "5.520642806743753\n",
      "6.6999974\n",
      "11.771257\n",
      "Saved Model, step is 18000\n",
      "Average loss is  7.286341475509107\n",
      "Saving PER and importance weights\n",
      "physactions  [ 0 10  0  0  0 20  8  5  6  5 15 15  5 15 10  0 15  5 10  5  5  5  0 10\n",
      "  0 15  5 15 15  0  0  5]\n",
      "chosen actions  [ 0  2 12  2 22 21  2 21 20  2 16  2  2 22 16 22 16 11  2  4  2 21 22  2\n",
      "  3  8 20 20  2  0  3 22]\n",
      "5.361734439586771\n",
      "6.4587493\n",
      "11.648205\n",
      "Saved Model, step is 19000\n",
      "Average loss is  7.379451587755233\n",
      "Saving PER and importance weights\n",
      "physactions  [ 4 20 24 15 24  5  0  0 24 10 20  0 23 15 13  5  0  0 10 15  0 17 20 10\n",
      " 20  5 24 15 20 20  0 20]\n",
      "chosen actions  [22  2 13  2 22 10 22  0  1 21 22  2 21  2  4  2 12 19 21  2 22 10  2 13\n",
      "  2 22 20  2  2  2  2  3]\n",
      "4.710937319130733\n",
      "5.9107976\n",
      "10.531421\n",
      "Saved Model, step is 20000\n",
      "Average loss is  7.143607961971313\n",
      "Saving PER and importance weights\n",
      "physactions  [15 20 19  5 15  0 15  0  0  0 20 10 15  0 15  0  0 15 11  0 10 10  5 10\n",
      " 20 21  5 15 15 15 20  0]\n",
      "chosen actions  [ 2  2 18 20 20 21  2  3 22 22 20  9 21  2  2 22 22 20 20 10 22 22  9 18\n",
      "  2  2  2 23 16 22  2  2]\n",
      "4.960700479047052\n",
      "6.1754346\n",
      "11.104165\n",
      "Saving results\n",
      "length IS  195421\n",
      "Saved Model, step is 21000\n",
      "Average loss is  6.731985422814265\n",
      "Saving PER and importance weights\n",
      "physactions  [20 10  3 20 20 17 24  5  0  5 19  5  0 10 12 10 10  0  6  0  0 10 15  5\n",
      " 15  0 10  5  5 24 15 18]\n",
      "chosen actions  [ 2  5 12  2 21  4 20 21  2  2 20 22  0  3 18 20 23  0  2  4  3 21 16 22\n",
      "  2 22  4 12  2  2  4  1]\n",
      "5.140931129455566\n",
      "6.6043215\n",
      "11.091974\n",
      "Saved Model, step is 22000\n",
      "Average loss is  6.631031049646437\n",
      "Saving PER and importance weights\n",
      "physactions  [ 0 15  5  4  5  0 13 11  5 10  0 10  0 20  0 10 10 20  5 15  5  5 10 15\n",
      "  5 20 15 18 20  0 10 20]\n",
      "chosen actions  [22  2  2  2  2  3 10  2 22 22 22 20  2 20 11 20  2  2  2  2  5  2 22 20\n",
      " 21 16 15  1 21 22  2 21]\n",
      "5.192973975477548\n",
      "6.7860503\n",
      "11.578862\n",
      "Saved Model, step is 23000\n",
      "Average loss is  6.623290018944536\n",
      "Saving PER and importance weights\n",
      "physactions  [15  0 15  5 20 20  6 20 13  5  0 20  0  0  0  0  0 10  0 20 15 20 20 10\n",
      " 23 15 15  6  0  0 10  0]\n",
      "chosen actions  [ 2 22  2 20  2 21 19 20  2  3  4 20  0 22  2 22  3  4 21  2 20 16 21  8\n",
      "  2 23 20  2 12  0 21  0]\n",
      "5.672697149474045\n",
      "7.5608897\n",
      "12.315258\n",
      "Saved Model, step is 24000\n",
      "Average loss is  6.651302931074053\n",
      "Saving PER and importance weights\n",
      "physactions  [ 0 10 15 15  0 15 15 20 10  5  0 11  5 15 20 15 10  0 20 20 10 24 15 13\n",
      "  0 15  5  5 10 10 10 15]\n",
      "chosen actions  [11 22 23  2 22  2 20 22  2 22  3 10  5  2  1 21 16  3 20 15 16 13 21  2\n",
      " 22 21  2 22 18  2  2 11]\n",
      "5.2058687703362825\n",
      "7.105941\n",
      "12.048556\n",
      "Saved Model, step is 25000\n",
      "Average loss is  6.527331578854471\n",
      "Saving PER and importance weights\n",
      "physactions  [15 20 23 15  5  0  0  5 10  7  5 10 15  5  5  0 15  0 20 10  5 20 10 15\n",
      "  0 24  5 15 20  5  5  0]\n",
      "chosen actions  [ 2  2  2 10  2 11 22 22 22 21  3 21 10 20  2  2 22  0 21 22 10 16 20  2\n",
      " 16 21  4 21 15  4 20  3]\n",
      "4.45332173643441\n",
      "6.4716644\n",
      "10.666829\n",
      "Saving results\n",
      "length IS  195421\n",
      "Saved Model, step is 26000\n",
      "Average loss is  6.307628412224353\n",
      "Saving PER and importance weights\n",
      "physactions  [10  5  5 10  5  5 10  0 10 22  5  5 10 23  5 20  0 16  0  0  0 23  4  0\n",
      "  5 20 21  0  5 15  5 16]\n",
      "chosen actions  [ 2  2 21  2 15 21  4 12 13 10 15 10 15 22 16 21  2 24  3  2  2  2  4  2\n",
      "  2 21 15 22 21 16  5 15]\n",
      "4.890333800480284\n",
      "6.7523956\n",
      "10.983968\n",
      "Saved Model, step is 27000\n",
      "Average loss is  6.009183663036675\n",
      "Saving PER and importance weights\n",
      "physactions  [23 20  0 13  5 11 19 13 15 15  5  0  6  5  0 12  0 20 20 15  5 19  0  5\n",
      " 21  0  0  5  0  4 12 10]\n",
      "chosen actions  [10  3 22  2  2 10  4 16 21  2  2 20  2 21  3  2 22  2 24 10  2 10 22  4\n",
      "  3 20  2 20  4  4  2  2]\n",
      "5.167017361213421\n",
      "6.724816\n",
      "10.960569\n",
      "Saved Model, step is 28000\n",
      "Average loss is  6.196180619649589\n",
      "Saving PER and importance weights\n",
      "physactions  [11 15 20  0  1  0 21 10  5 10 15  0  0  0  0 20 11 15  0 20 21  0 15 10\n",
      " 20  5 10  0  5  0 20 10]\n",
      "chosen actions  [13 10  2 20 11  2 13  2 21  2 24 22 22 20  0 16 22 10 22  2 10  2  5 10\n",
      "  1  2 15 10 20  2  2  2]\n",
      "5.0504070808147565\n",
      "6.9162025\n",
      "11.652429\n",
      "Saved Model, step is 29000\n",
      "Average loss is  6.325059918503277\n",
      "Saving PER and importance weights\n",
      "physactions  [ 0 20 22  5  0  0  0 20 20 14 20 10 10 24 10  0  0 10 17  5 15 17  0  0\n",
      " 15  0  5  7  0 15 20 24]\n",
      "chosen actions  [22  2  2  2 16  3 22  2 15  2  2  2 22 10 15  3  3  2 22 20  5  2  0  2\n",
      " 10  4 10 22  2 10 21 19]\n",
      "4.941660913927802\n",
      "6.6463675\n",
      "11.391138\n",
      "Saved Model, step is 30000\n",
      "Average loss is  6.017943202536554\n",
      "Saving PER and importance weights\n",
      "physactions  [ 5  0  0 15 10 10 13 13  5 20  0  0  5 15  0  8  0 15 10  0  0  0 20 20\n",
      "  5  0 10 10  5 15 10 24]\n",
      "chosen actions  [ 2  2  2  2  5  5  2  2 21  5 21  4 11 20  0  2 22 10 22  0  2 22 10  2\n",
      "  2 16 22 10 11 20 12  1]\n",
      "5.238912533069479\n",
      "7.082147\n",
      "11.49935\n",
      "Saving results\n",
      "length IS  195421\n",
      "Saved Model, step is 31000\n",
      "Average loss is  5.881384750302881\n",
      "Saving PER and importance weights\n",
      "physactions  [15  5 15  0  0  5  0  0  0 20 10  0 23 16  5  0  0 15 20 24  0 16 15 17\n",
      " 10  0  5  0 20 20  5  0]\n",
      "chosen actions  [ 9 21 15  0 11  5 22  0 22  2  2  0 21 18  2 22  0  2 21  2  3 10  2  1\n",
      "  2 22 20  2  5 10 12  0]\n",
      "5.213662032423349\n",
      "7.1490636\n",
      "11.5591545\n",
      "Saved Model, step is 32000\n",
      "Average loss is  5.700187491558492\n",
      "Saving PER and importance weights\n",
      "physactions  [10  0  5 22 20  3  5  5 10 18 15  5 10  5 15 10  0  5  0  5  5  0  5 17\n",
      " 15 17 15 17  0  0  0 20]\n",
      "chosen actions  [ 5 22  4 15 15 22 21  5 21  2 21 22 22 12  2 10 22  5  3 16  2  3 22 15\n",
      " 21  2 23 10  3  3 22  2]\n",
      "5.3666733051168505\n",
      "7.4909835\n",
      "11.835803\n",
      "Saved Model, step is 33000\n",
      "Average loss is  5.635241834711284\n",
      "Saving PER and importance weights\n",
      "physactions  [ 5 23 10  0  0 24 22  5  0  0 22  0  0 20  0 19 10 15  0 20 15 24 15  0\n",
      "  5 15 10  5  0 15  5 15]\n",
      "chosen actions  [ 2  1  2 22 22  1 21  2  4  3  1 22  0  5  0  2 15  2 20 16 22  2 10  3\n",
      "  2 13  4 15 22  9 22 10]\n",
      "5.374288822042531\n",
      "7.655933\n",
      "11.690195\n",
      "Saved Model, step is 34000\n",
      "Average loss is  5.386248301073909\n",
      "Saving PER and importance weights\n",
      "physactions  [22 20  0  0  8  0  5 21  5  5  0 24 10  0 20  5 10  8  1  0 18  5 15  0\n",
      " 15 12  5  0 20  5 20 15]\n",
      "chosen actions  [15 23 10 16 10 22 20 23 22  2  3 21 21  3 15 20 18 24  0 22  2 15  2  9\n",
      "  2 22  5 22 10  2 16 23]\n",
      "5.246704775711586\n",
      "7.6259093\n",
      "11.12717\n",
      "Saved Model, step is 35000\n",
      "Average loss is  5.525465456362814\n",
      "Saving PER and importance weights\n",
      "physactions  [ 0  0 15  0  0  5  5 15  0 15  5 15 15  0  5 10  0 24  5 15 10  5  0 22\n",
      " 10  0 10  5  0 18 20  5]\n",
      "chosen actions  [22  4  2  0 10  2 22  2 22  1  2  2 15 22  3 23  3 13 15 10 21  5 21 23\n",
      " 15  4  2 12 22  2 16 22]\n",
      "4.770928366430875\n",
      "7.0222197\n",
      "10.506396\n",
      "Saving results\n",
      "length IS  195421\n",
      "Saved Model, step is 36000\n",
      "Average loss is  5.452707596693188\n",
      "Saving PER and importance weights\n",
      "physactions  [ 0  0 20 20 16  0  0  0  6 24 13  1  5 10  5 20  6 22 11  0  3 15  0  8\n",
      " 12  5 10 20 20 18 24 20]\n",
      "chosen actions  [10  3  2 20 15  0  0  3  1 15  2  0 12 21 10 15 10  2  2  0  3  2 16 10\n",
      " 15 15  3 21 15 23 16 21]\n",
      "5.357613333340349\n",
      "7.965884\n",
      "11.833291\n",
      "Saved Model, step is 37000\n",
      "Average loss is  5.523308573450893\n",
      "Saving PER and importance weights\n",
      "physactions  [17 20  0  0 18 18  0  0  0  0  0 10 15 12  5 10  5  0  0  5 10  0 10  5\n",
      "  5  0  5  5  0  0  0  0]\n",
      "chosen actions  [12 15  3 22  2  2 20  3 22 10 10  2 21 18  1 21 19 22  5 15 21  5  4 21\n",
      " 16 20 10 15 22 22 16  3]\n",
      "4.450929427969045\n",
      "6.694435\n",
      "10.964714\n",
      "Saved Model, step is 38000\n",
      "Average loss is  5.700156120114029\n",
      "Saving PER and importance weights\n",
      "physactions  [ 0 15 15 10 15 15 11 16  5  5 10  0  5  0 15 15  5 15  5  0 15 20  0  5\n",
      "  0 10  0 15 10 10  0 15]\n",
      "chosen actions  [ 3 21  2  2  5  5  2 16 20 24  2 22 10  0 22 22 22 24 10  0 23 23 12  2\n",
      "  2  2  2 22  3 22 22  2]\n",
      "4.123593494809907\n",
      "6.572107\n",
      "10.011148\n",
      "Saved Model, step is 39000\n",
      "Average loss is  5.487960888780654\n",
      "Saving PER and importance weights\n",
      "physactions  [15  0 15  6 20  5  0 15 23 10  0  0 15  5 11  5 10  5 15 10 15 24 15  0\n",
      "  5  5  5 10  5 10 23 15]\n",
      "chosen actions  [21  0  5  2 15  3  3  5  1 22 22 22  2  3  5  2 15 22  4 22  2 13 21  0\n",
      "  2  2  4  2  3  2 23 16]\n",
      "4.47804962355515\n",
      "6.753031\n",
      "10.446217\n",
      "length IS  195421\n"
     ]
    }
   ],
   "source": [
    "# The main training loop is here\n",
    "per_alpha = 0.6 # PER hyperparameter\n",
    "per_epsilon = 0.01 # PER hyperparameter\n",
    "batch_size = 32\n",
    "gamma = 0.99 # discount factor \n",
    "num_steps = 40000 # How many steps to train for\n",
    "load_model = False #Whether to load a saved model.\n",
    "save_dir = \"./vasochange4_dqn_normal_10/\"\n",
    "save_path = \"./vasochange4_dqn_normal_10/ckpt\"#The path to save our model to.\n",
    "tau = 0.001 #Rate to update target network toward primary network\n",
    "tf.reset_default_graph()\n",
    "mainQN = Qnetwork()\n",
    "targetQN = Qnetwork()\n",
    "av_q_list = []\n",
    "\n",
    "val_abserror_list = []\n",
    "abs_error_list = []\n",
    "save_results = False\n",
    "\n",
    "saver = tf.train.Saver(tf.global_variables())\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "trainables = tf.trainable_variables()\n",
    "\n",
    "target_ops = update_target_graph(trainables,tau)\n",
    "\n",
    "#Make a path for our model to be saved in.\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "\n",
    "with tf.Session(config=config) as sess:\n",
    "    if load_model == True:\n",
    "        print('Trying to load model...')\n",
    "        try:\n",
    "            restorer = tf.train.import_meta_graph(save_path + '.meta')\n",
    "            restorer.restore(sess, tf.train.latest_checkpoint(save_dir))\n",
    "            print (\"Model restored\")\n",
    "        except IOError:\n",
    "            print (\"No previous model found, running default init\")\n",
    "            sess.run(init)\n",
    "        try:\n",
    "            per_weights = pickle.load(open( save_dir + \"per_weights.p\", \"rb\" ))\n",
    "            imp_weights = pickle.load(open( save_dir + \"imp_weights.p\", \"rb\" ))\n",
    "            \n",
    "            # the PER weights, governing probability of sampling, and importance sampling\n",
    "            # weights for use in the gradient descent updates\n",
    "            df['prob'] = per_weights\n",
    "            df['imp_weight'] = imp_weights\n",
    "            print (\"PER and Importance weights restored\")\n",
    "        except IOError:\n",
    "            print(\"No PER weights found - default being used for PER and importance sampling\")\n",
    "    else:\n",
    "        print(\"Running default init\")\n",
    "        sess.run(init)\n",
    "    print(\"Init done\")\n",
    "    \n",
    "    net_loss = 0.0\n",
    "    for i in range(num_steps):\n",
    "        if save_results:\n",
    "            print( \"Calling do save results\")\n",
    "            do_save_results()\n",
    "            break\n",
    "        \n",
    "        states,actions,rewards,next_states, done_flags, sampled_df = process_train_batch(batch_size)\n",
    "        \n",
    "        # firstly get the chosen actions at the next timestep\n",
    "        actions_from_q1 = sess.run(mainQN.predict,feed_dict={mainQN.state:next_states, mainQN.phase : 1})\n",
    "        \n",
    "        # actions chosen now, as a check\n",
    "        cur_act = sess.run(mainQN.predict,feed_dict={mainQN.state:states, mainQN.phase : 1})\n",
    "        cur_vasodose = np.array([action_dose_map[i] for i in cur_act], dtype= np.float32)\n",
    "\n",
    "        # Q values for the next timestep from target network, as part of the Double DQN update\n",
    "        Q2 = sess.run(targetQN.q_output,feed_dict={targetQN.state:next_states, targetQN.phase : 1})\n",
    "\n",
    "        # handles the case when a trajectory is finished\n",
    "        end_multiplier = 1 - done_flags\n",
    "    \n",
    "        # target Q value using Q values from target, and actions from main\n",
    "        double_q_value = Q2[range(len(Q2)),actions_from_q1]\n",
    "        \n",
    "        # empirical hack to make the Q values never exceed the threshold - helps learning\n",
    "        double_q_value[double_q_value > REWARD_THRESHOLD] = REWARD_THRESHOLD\n",
    "        double_q_value[double_q_value < -REWARD_THRESHOLD] = -REWARD_THRESHOLD\n",
    "        \n",
    "        # definition of target Q\n",
    "        targetQ = rewards + (gamma*double_q_value * end_multiplier)\n",
    "\n",
    "\n",
    "        # Calculate the importance sampling weights for PER\n",
    "        imp_sampling_weights = np.array(sampled_df['imp_weight'] / float(max(df['imp_weight'])))\n",
    "        imp_sampling_weights[np.isnan(imp_sampling_weights)] = 1\n",
    "        imp_sampling_weights[imp_sampling_weights <= 0.001] = 0.001\n",
    "\n",
    "        # Train with the batch\n",
    "        _,loss, error = sess.run([mainQN.update_model,mainQN.loss, mainQN.abs_error], \\\n",
    "            feed_dict={mainQN.state:states,\n",
    "                       mainQN.targetQ:targetQ, \n",
    "                       mainQN.actions:actions,\n",
    "                       mainQN.cur_vasodose:cur_vasodose,\n",
    "                       mainQN.phase:True,\n",
    "                       mainQN.imp_weights:imp_sampling_weights})\n",
    "\n",
    "        # Update target towards main network\n",
    "        update_target(target_ops,sess)\n",
    "        \n",
    "        net_loss += sum(error)\n",
    "        \n",
    "        # Set the selection weight/prob to the abs prediction error and update the importance sampling weight\n",
    "        new_weights = pow((error + per_epsilon), per_alpha)\n",
    "        df.loc[df.index.isin(sampled_df.index), 'prob'] = new_weights\n",
    "        temp = 1.0/new_weights\n",
    "        df.loc[df.index.isin(sampled_df.index), 'imp_weight'] = pow(((1.0/len(df)) * temp), beta_start)\n",
    "        \n",
    "        if i % 1000 == 0 and i > 0:\n",
    "            saver.save(sess,save_path)\n",
    "            print(\"Saved Model, step is \" + str(i))\n",
    "            \n",
    "            av_loss = net_loss/(1000.0 * batch_size)\n",
    "            abs_error_list.append(av_loss)\n",
    "            \n",
    "            print(\"Average loss is \", av_loss)\n",
    "            net_loss = 0.0\n",
    "                        \n",
    "            print (\"Saving PER and importance weights\")\n",
    "            with open(save_dir + 'per_weights.p', 'wb') as f:\n",
    "                pickle.dump(df['prob'], f)\n",
    "            with open(save_dir + 'imp_weights.p', 'wb') as f:\n",
    "                pickle.dump(df['imp_weight'], f)\n",
    "            \n",
    "            \n",
    "           #        if (i % 5000==0) and i > 0:\n",
    "            print (\"physactions \", actions)\n",
    "            print (\"chosen actions \", cur_act)\n",
    "            #run an evaluation on the validation set\n",
    "            phys_q, phys_actions, agent_q, agent_actions, mean_abs_error = do_eval(eval_type = 'val')            \n",
    "            val_abserror_list.append(mean_abs_error/29)  \n",
    "            \n",
    "            print (mean_abs_error/29)\n",
    "            print (np.mean(phys_q))\n",
    "            print (np.mean(agent_q))\n",
    "\n",
    "            if (i % 5000==0) and i > 0:\n",
    "                print (\"Saving results\")\n",
    "                do_save_results()\n",
    "    \n",
    "    do_save_results()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(abs_error_list, label = 'train_loss')\n",
    "plt.plot(val_abserror_list, label = 'val_loss')\n",
    "plt.title('q network model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('train steps*1000')\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
