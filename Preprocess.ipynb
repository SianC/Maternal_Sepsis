{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is based on https://github.com/aniruddhraghu/sepsisrl/blob/master/preprocessing/process_interventions.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas import DataFrame\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_data = pd.read_csv(\"../Matlab/MIMIC_mimiciii.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "interventions = orig_data[[\"max_dose_vaso\", \"input_4hourly\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjusted_vaso = interventions[\"max_dose_vaso\"][interventions[\"max_dose_vaso\"] >0]\n",
    "adjusted_iv = interventions[\"input_4hourly\"][interventions[\"input_4hourly\"]>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vaso_quartiles = adjusted_vaso.quantile([0.25,0.50,0.75])\n",
    "iv_quartiles = adjusted_iv.quantile([0.25,0.5,0.75])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.08, 0.2 , 0.45])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vq = np.array(vaso_quartiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 48.2670625, 150.       , 500.       ])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ivq = np.array(iv_quartiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "discretised_int = copy.deepcopy(interventions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "discretised_int['vaso_input'] = discretised_int['max_dose_vaso']\n",
    "discretised_int['vaso_input'][interventions['max_dose_vaso'] == 0.0] = 0\n",
    "discretised_int['vaso_input'][(interventions['max_dose_vaso'] > 0.0) & (interventions['max_dose_vaso'] < vq[0])] = 1\n",
    "discretised_int['vaso_input'][(interventions['max_dose_vaso'] >= vq[0]) & (interventions['max_dose_vaso'] < vq[1])] = 2\n",
    "discretised_int['vaso_input'][(interventions['max_dose_vaso'] >= vq[1]) & (interventions['max_dose_vaso'] < vq[2])] = 3\n",
    "a = interventions['max_dose_vaso'] >= vq[2]\n",
    "discretised_int['vaso_input'][a] = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "discretised_int['iv_input'] = discretised_int['input_4hourly']\n",
    "discretised_int['iv_input'][interventions['input_4hourly'] == 0.0] = 0\n",
    "discretised_int['iv_input'][(interventions['input_4hourly'] > 0.0) & (interventions['input_4hourly'] < ivq[0])] = 1\n",
    "discretised_int['iv_input'][(interventions['input_4hourly'] >=  ivq[0]) & (interventions['input_4hourly'] <  ivq[1])] = 2\n",
    "discretised_int['iv_input'][(interventions['input_4hourly'] >=  ivq[1]) & (interventions['input_4hourly'] < ivq[2])] = 3\n",
    "discretised_int['iv_input'][(interventions['input_4hourly'] >=  ivq[2])] = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "disc_inp_data = copy.deepcopy(orig_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "disc_inp_data['vaso_input'] = discretised_int['vaso_input']\n",
    "disc_inp_data['iv_input'] = discretised_int['iv_input']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "actions = []\n",
    "for i, row in disc_inp_data.iterrows():\n",
    "    if row[\"vaso_input\"] == 0:\n",
    "        if row[\"iv_input\"] == 0:\n",
    "            actions.append(0)\n",
    "        elif row[\"iv_input\"] == 1:\n",
    "            actions.append(5)\n",
    "        elif row[\"iv_input\"] == 2:\n",
    "            actions.append(10)\n",
    "        elif row[\"iv_input\"] == 3:\n",
    "            actions.append(15)\n",
    "        else:\n",
    "            actions.append(20)\n",
    "    elif row[\"vaso_input\"] == 1:\n",
    "        if row[\"iv_input\"] == 0:\n",
    "            actions.append(1)\n",
    "        elif row[\"iv_input\"] == 1:\n",
    "            actions.append(6)\n",
    "        elif row[\"iv_input\"] == 2:\n",
    "            actions.append(11)\n",
    "        elif row[\"iv_input\"] == 3:\n",
    "            actions.append(16)\n",
    "        else:\n",
    "            actions.append(21)\n",
    "    elif row[\"vaso_input\"] == 2:\n",
    "        if row[\"iv_input\"] == 0:\n",
    "            actions.append(2)\n",
    "        elif row[\"iv_input\"] == 1:\n",
    "            actions.append(7)\n",
    "        elif row[\"iv_input\"] == 2:\n",
    "            actions.append(12)\n",
    "        elif row[\"iv_input\"] == 3:\n",
    "            actions.append(17)\n",
    "        else:\n",
    "            actions.append(22)\n",
    "    elif row[\"vaso_input\"] == 3:\n",
    "        if row[\"iv_input\"] == 0:\n",
    "            actions.append(3)\n",
    "        elif row[\"iv_input\"] == 1:\n",
    "            actions.append(8)\n",
    "        elif row[\"iv_input\"] == 2:\n",
    "            actions.append(13)\n",
    "        elif row[\"iv_input\"] == 3:\n",
    "            actions.append(18)\n",
    "        else:\n",
    "            actions.append(23)\n",
    "    else:\n",
    "        if row[\"iv_input\"] == 0:\n",
    "            actions.append(4)\n",
    "        elif row[\"iv_input\"] == 1:\n",
    "            actions.append(9)\n",
    "        elif row[\"iv_input\"] == 2:\n",
    "            actions.append(14)\n",
    "        elif row[\"iv_input\"] == 3:\n",
    "            actions.append(19)\n",
    "        else:\n",
    "            actions.append(24)\n",
    "disc_inp_data[\"action\"] = actions    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "disc_inp_data.to_csv('../Fresh_start/discretised_input_data_MIMIC_mimiciii.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data saved and re-read so code can be paused here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../Fresh_start/discretised_input_data_MIMIC_mimiciii.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c0 = -0.1/4\n",
    "c1 = -0.5/4\n",
    "c2 = -2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add rewards\n",
    "df[\"mortality_90d\"] = df[\"mortality_90d\"].fillna(0)\n",
    "df['reward'] = 0\n",
    "for i in df.index:\n",
    "    if i == 0:\n",
    "        continue\n",
    "    # add intermediate rewards\n",
    "    elif df.loc[i, 'icustayid'] == df.loc[i-1, 'icustayid']:\n",
    "        sofa_cur = df.loc[i,'SOFA']\n",
    "        sofa_prev = df.loc[i-1,'SOFA']\n",
    "        lact_cur = df.loc[i,'Arterial_lactate']\n",
    "        lact_prev = df.loc[i-1,'Arterial_lactate']\n",
    "        reward = 0\n",
    "        if sofa_cur == sofa_prev and sofa_cur != 0:\n",
    "            reward += c0\n",
    "        reward += c1*(sofa_cur-sofa_prev)\n",
    "        reward += c2*np.tanh(lact_cur - lact_prev)\n",
    "        df.loc[i-1,'reward'] = reward\n",
    "    \n",
    "    #Add final rewards\n",
    "    elif df.loc[i, 'icustayid'] != df.loc[i-1, 'icustayid']:\n",
    "        if df.loc[i-1, 'mortality_90d'] == 1.0:\n",
    "                df.loc[i-1,'reward'] = -15\n",
    "                \n",
    "        elif df.loc[i-1, 'mortality_90d'] == 0.0:\n",
    "            df.loc[i-1,'reward'] = 15\n",
    "        else:\n",
    "            print(\"error in row\", i-1)\n",
    "    elif i % 10000 == 0:\n",
    "        print(i)\n",
    "if df.loc[len(df)-1, 'mortality_90d'] == 1.0:\n",
    "    df.loc[len(df)-1, 'reward'] = -15\n",
    "elif df.loc[len(df)-1, 'mortality_90d'] == 0.0:\n",
    "     df.loc[len(df)-1, 'reward'] = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../Fresh_start/did_MIMIC_mimiciii_with_rewards.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data saved and re-read so code can be paused here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disc_inp_data = pd.read_csv('../Fresh_start/did_MIMIC_mimiciii_with_rewards.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now split into train/validation/test sets\n",
    "import random\n",
    "unique_ids = disc_inp_data['icustayid'].unique()\n",
    "random.shuffle(unique_ids)\n",
    "train_sample = 0.7\n",
    "val_sample = 0.1\n",
    "test_sample = 0.2\n",
    "train_num = int(len(unique_ids) * 0.7)\n",
    "val_num = int(len(unique_ids)*0.1) + train_num\n",
    "train_ids = unique_ids[:train_num]\n",
    "val_ids = unique_ids[train_num:val_num]\n",
    "test_ids = unique_ids[val_num:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = DataFrame()\n",
    "train_set = disc_inp_data.loc[disc_inp_data['icustayid'].isin(train_ids)]\n",
    "\n",
    "val_set = DataFrame()\n",
    "val_set = disc_inp_data.loc[disc_inp_data['icustayid'].isin(val_ids)]\n",
    "\n",
    "test_set = DataFrame()\n",
    "test_set = disc_inp_data.loc[disc_inp_data['icustayid'].isin(test_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pregnant_set = pd.read_csv(\"../Matlab/pregnant_data_nn.csv\")\n",
    "control_1_set = pd.read_csv(\"../Matlab/control_1_data_nn.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pregnant_ids = pregnant_set[\"icustayid\"]\n",
    "control_1_ids = control_1_set[\"icustayid\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_fields = ['gender','mechvent','re_admission']\n",
    "norm_fields= ['age','Weight_kg','GCS','HR','SysBP','MeanBP','DiaBP','RR','Temp_C','FiO2_1',\n",
    "    'Potassium','Sodium','Chloride','Glucose','Magnesium','Calcium',\n",
    "    'Hb','WBC_count','Platelets_count','PTT','PT','Arterial_pH','paO2','paCO2',\n",
    "    'Arterial_BE','HCO3','Arterial_lactate','SOFA','SIRS','Shock_Index',\n",
    "    'PaO2_FiO2','cumulated_balance', 'elixhauser', 'Albumin', u'CO2_mEqL', 'Ionised_Ca']\n",
    "log_fields = ['max_dose_vaso','SpO2','BUN','Creatinine','SGOT','SGPT','Total_bili','INR',\n",
    "              'input_total','input_4hourly','output_total','output_4hourly', 'bloc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set[binary_fields] = train_set[binary_fields] - 0.5 \n",
    "val_set[binary_fields] = val_set[binary_fields] - 0.5 \n",
    "test_set[binary_fields] = test_set[binary_fields] - 0.5\n",
    "pregnant_set[binary_fields] = pregnant_set[binary_fields] - 0.5\n",
    "control_1_set[binary_fields] = control_1_set[binary_fields] - 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normal distn fields\n",
    "for item in norm_fields:\n",
    "    av = train_set[item].mean()\n",
    "    #av = disc_inp_data[item].mean()\n",
    "    std = train_set[item].std()\n",
    "    #std = disc_inp_data[item].std()\n",
    "    train_set[item] = (train_set[item] - av) / std\n",
    "    val_set[item] = (val_set[item] - av) / std\n",
    "    test_set[item] = (test_set[item] - av) / std\n",
    "    pregnant_set[item] = (pregnant_set[item] - av) / std\n",
    "    control_1_set[item] = (control_1_set[item] - av) / std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log normal fields\n",
    "train_set[log_fields] = np.log(0.1 + train_set[log_fields])\n",
    "val_set[log_fields] = np.log(0.1 + val_set[log_fields])\n",
    "test_set[log_fields] = np.log(0.1 + test_set[log_fields])\n",
    "pregnant_set[log_fields] = np.log(0.1 + pregnant_set[log_fields])\n",
    "control_1_set[log_fields] = np.log(0.1 + control_1_set[log_fields])\n",
    "for item in log_fields:\n",
    "    av = train_set[item].mean()\n",
    "    #av = disc_inp_data[item].mean()\n",
    "    std = train_set[item].std()\n",
    "    #std = disc_inp_data[item].std()\n",
    "    train_set[item] = (train_set[item] - av) / std\n",
    "    val_set[item] = (val_set[item] - av) / std\n",
    "    test_set[item] = (test_set[item] - av) / std\n",
    "    pregnant_set[item] = (pregnant_set[item] - av) / std\n",
    "    control_1_set[item] = (control_1_set[item] - av) / std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set.to_csv('../Fresh_start/rl_train_set_unscaled_rewarded.csv',index = False)\n",
    "val_set.to_csv('../Fresh_start/rl_val_set_unscaled_rewarded.csv', index = False)\n",
    "test_set.to_csv('../Fresh_start/rl_test_set_unscaled_rewarded.csv', index = False)\n",
    "pregnant_set.to_csv('../Fresh_start/rl_pregnant_set_unscaled_rewarded.csv', index = False)\n",
    "control_1_set.to_csv('../Fresh_start/rl_control_1_set_unscaled_rewarded.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale features to [0,1] in train set, similar in val and test\n",
    "import copy\n",
    "scalable_fields = copy.deepcopy(binary_fields)\n",
    "scalable_fields.extend(norm_fields)\n",
    "scalable_fields.extend(log_fields)\n",
    "for col in scalable_fields:\n",
    "    minimum = min(train_set[col])\n",
    "    #minimum = min(disc_inp_data[col])\n",
    "    maximum = max(train_set[col])\n",
    "    #maximum = max(disc_inp_data[col])\n",
    "    train_set[col] = (train_set[col] - minimum)/(maximum-minimum)\n",
    "    val_set[col] = (val_set[col] - minimum)/(maximum-minimum)\n",
    "    test_set[col] = (test_set[col] - minimum)/(maximum-minimum)\n",
    "    pregnant_set[col] = (pregnant_set[col] - minimum)/(maximum-minimum)\n",
    "    control_1_set[col] = (control_1_set[col] - minimum)/(maximum-minimum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set.to_csv('../Fresh_start/rl_train_set_scaled_rewarded.csv',index = False)\n",
    "val_set.to_csv('../Fresh_start/rl_val_set_scaled_rewarded.csv', index = False)\n",
    "test_set.to_csv('../Fresh_start/rl_test_set_scaled_rewarded.csv', index = False)\n",
    "pregnant_set.to_csv('../Fresh_start/rl_pregnant_set_scaled_rewarded.csv', index = False)\n",
    "control_1_set.to_csv('../Fresh_start/rl_control_1_set_scaled_rewarded.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set[\"max_dose_vaso_unnorm\"] = disc_inp_data[\"max_dose_vaso\"].loc[disc_inp_data['icustayid'].isin(train_ids)]\n",
    "val_set[\"max_dose_vaso_unnorm\"] = disc_inp_data[\"max_dose_vaso\"].loc[disc_inp_data['icustayid'].isin(val_ids)]\n",
    "test_set[\"max_dose_vaso_unnorm\"] = disc_inp_data[\"max_dose_vaso\"].loc[disc_inp_data['icustayid'].isin(test_ids)]\n",
    "pregnant_set[\"max_dose_vaso_unnorm\"] = disc_inp_data[\"max_dose_vaso\"].loc[disc_inp_data['icustayid'].isin(pregnant_ids)].reset_index()[\"max_dose_vaso\"]\n",
    "control_1_set[\"max_dose_vaso_unnorm\"] = disc_inp_data[\"max_dose_vaso\"].loc[disc_inp_data['icustayid'].isin(control_1_ids)].reset_index()[\"max_dose_vaso\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_abchange_vc(df):\n",
    "    abchange_vc_list = [0]\n",
    "    for i, row in df.iterrows():\n",
    "        if i == 0:\n",
    "            prev_vc = row[\"max_dose_vaso_unnorm\"]\n",
    "        else:\n",
    "            #print(\"eyyy\")\n",
    "            abchange_vc = row[\"max_dose_vaso_unnorm\"] - prev_vc\n",
    "            abchange_vc_list.append(abchange_vc)\n",
    "            prev_vc = row[\"max_dose_vaso_unnorm\"]\n",
    "            #if i == 100:\n",
    "                #break\n",
    "    df.head()\n",
    "    df[\"abchange_vc\"] = abchange_vc_list\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = train_set.reset_index()\n",
    "train_set = add_abchange_vc(train_set)\n",
    "test_set = test_set.reset_index()\n",
    "val_set = val_set.reset_index()\n",
    "test_set = add_abchange_vc(test_set)\n",
    "val_set = add_abchange_vc(val_set)\n",
    "pregnant_set = pregnant_set.reset_index()\n",
    "pregnant_set = add_abchange_vc(pregnant_set)\n",
    "control_1_set = control_1_set.reset_index()\n",
    "control_1_set = add_abchange_vc(control_1_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set.to_csv('../Fresh_start/rl_train_set_scaled_rewarded_abchange.csv',index = False)\n",
    "val_set.to_csv('../Fresh_start/rl_val_set_scaled_rewarded_abchange.csv', index = False)\n",
    "test_set.to_csv('../Fresh_start/rl_test_set_scaled_rewarded_abchange.csv', index = False)\n",
    "pregnant_set.to_csv('../Fresh_start/rl_pregnant_set_scaled_rewarded_abchange.csv', index = False)\n",
    "control_1_set.to_csv('../Fresh_start/rl_control_1_set_scaled_rewarded_abchange.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
